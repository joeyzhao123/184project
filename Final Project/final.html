<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS184 Final Project Group 64: Minecraft Shaders</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Final Project Group 64: Minecraft Shaders</h1>
<h2 align="middle">Joey Zhao, Massimo Tseng, Jason Gong, Shawn Zhao</h2>
<br><br>

<h2 align="middle">Overview</h2>
<p>
  Our final project involved writing our own shaders in Minecraft in order to introduce different graphical effects that the base game lacks. We implemented shadow mapping, bloom, screen space reflections, rippling water and swaying leaves, and atmospheric lighting. These effects, when combined together, provide a more immersive gaming experience with the improved visuals.
</p>


<h2 align="middle">Shadow Mapping</h2>

<p>
  At a high level overview, shadow mapping is just casting a shadow on pixels that do not have a direct line of sight to the sun. 
  In theory, it’s easy but the implementation was a lot more involved. We followed the reference at http://www.opengl-tutorial.org/intermediate-tutorials/tutorial-16-shadow-mapping/.
<br>
To start, we used shadowtex0, which is a shadow map that is provided by Optifine. We then use matrix calculations on our texture coordinate to move it into shadow space. This is accomplished by first moving to world space, and then shadow space. We compare texture coordinate sample to its equivalent point in the shadow map. If the depth of our texture is greater than that of the shadow map, our texture is further away from the sun, meaning it is in a shadow. 
</p>
<div align="middle">
  <img src="images/shadowmapgraphic.png" align="middle" width="800px"/>
  </div>

  <p>
    After implementing this check, we need to also implement a distortion algorithm for the shadows. The algorithm we chose was augmenting the x and y by (cuberoot(abs(x^3 + y^3))). We also scaled the z by 1.2. This algorithm was chosen based on trials we did with different algorithms. Ultimately, this one worked the best.
  <br>
  How we specifically chose to ultimately write the shadow was based on a check if the normal of the texture was perpendicular to the normal of the sun. The reason for this is that without this check, we get weird fragmenting on the sides of blocks due to small calculation errors.
  </p>
  <div align="middle">
    <img src="images/weirdfragments.png" align="middle" width="800px"/>
    </div>

  <p>
    This effect took the longest to debug. We tried various methods such as clamping some values and changing the distortion algorithm.
<br>In the end result, we were able to create these great shadow effects.

  </p>
  <div align="middle">
    <img src="images/finalshadowbase.png" align="middle" width="800px"/>
    <figcaption>Default Scene</figcaption>

    </div>
  <div align="middle">
    <img src="images/finalshadow.png" align="middle" width="800px"/>
    <figcaption>Shader Scene</figcaption>

    </div>

<h2 align="middle">Bloom</h2>
<p>
  Bloom is a post processing effect that aims to reproduce the glow effects we see in real life of emissive objects. There are two main approaches to implementing a bloom effect: an HDR bloom and a thresholding bloom. We chose the latter because of limitations in the optifine pipeline; however, HDR bloom is indeed possible to implement.  <br>
For thresholding bloom, we want to first find the bright blocks, draw that to a separate texture, blur this texture, then blend it back into the original. In order to find the bright blocks, we first have to calculate perceived brightness, or relative luminance. We dot the color vector with a predefined constant vector that reflects the luminance efficiency function we learned in lecture. The colors that exceed a certain threshold are counted as “bright”. A problem we faced is that because there is no HDR support, there is effectively no difference between a white flower and a glowing torch. To combat this, we checked block ids and if the block didn’t count as an emissive object, the overall bloom was heavily attenuated. If the threshold was not met, black is returned. 
</p>
<div align="middle">
	<table style="width=100%">
	  <tr>
		<td>		
			<img src="images/extracted_color.png" align="middle" width="400px"/>
			<figcaption align="middle">Extracted colors</figcaption>
		</td>
	  </tr>
	</table>
</div>
<p>
After writing the bright textures to a separate drawbuffer, we want to blur it. A common technique is to use a Gaussian filter for a smooth and natural blur. While easy to implement naively, it is extremely inefficient. With a modest filter size of 30, each fragment will take at least 900 samples. In practice, this drops framerates on a powerful graphics card from over 165 frames to about 30 frames a second. Thankfully, a great property of the Gaussian is that it is a separable equation. Therefore, we create two separate passes, one for the horizontal blur and one for the vertical blur. This significantly reduces runtime, now 60 samples, and creates the same effect. To add an even grittier (and subjectively better) look to the final bloom, we blurred further with two passes of a box filter. Finally, we add this texture to the original to complete the effect: 
</p>

<div align="middle">
	<table style="width=100%">
	  <tr>
		<td>		
			<img src="images/blurred_color.png" align="middle" width="400px"/>
			<figcaption align="middle">Blurred colors</figcaption>
		</td>
		<td>		
			<img src="images/bloom.png" align="middle" width="400px"/>
			<figcaption align="middle">Final bloom effect</figcaption>
    </td>
	  </tr>
	</table>
</div>
<p>
As an aside, implementing an HDR bloom does not require the bright light extraction step; we simply blur and blend together with a strong bias towards the original HDR texture and we get a great bloom effect. This is because with HDR, bright colors are inherently biased. 
<br>
We learned that multiple passes are extraordinarily useful not only for clean and integrable code but also for implementing separable filters!
</p>

<h2 align="middle">Atmospheric Lighting</h2>
<p>
  In this section, we implemented atmospheric lighting. In base minecraft, the sun and the moon are merely textures placed in a monocolor sky. As such, they look like they have little to no illumination:
</p>

<div align="middle">
	<table style="width=100%">
	  <tr>
		<td>		
			<img src="images/base_sun.png" align="middle" width="400px"/>
			<figcaption align="middle">Base sun</figcaption>
		</td>
		<td>		
			<img src="images/base_moon.png" align="middle" width="400px"/>
			<figcaption align="middle">Base moon</figcaption>
    </td>
	  </tr>
	</table>
</div>

<p>
  However, in reality, the atmosphere enhances ambient lighting by scattering light from the sun or moon. For visual effect, we can achieve this by treating the sun or moon as an illuminating object in the sky, and then incorporating their radiance into nearby sky fragments in the fragment shader step with some sort of radiance falloff rule.
</p>

<p>
  Minecraft does not render any physical sun, moon, or sky blocks. Instead, these entities are represented as coordinates in view space, and thus act as normalized vectors from your viewing position to the angular position where the sun or specific fragment of sky is. We use this information to simulate a “distance to the sun/moon” metric by projecting the view vector of the sky fragment onto the sun/moon vector, where the shorter the projection is, the farther away the sky fragment is. We then used this distance metric to determine how much light and color we should add from the sun/moon to the relevant sky fragments. One thing to note from lecture is that we learned that irradiance falloff follows the inverse square law in the real world, but sometimes it has to be changed for visual effect. This idea definitely applied here, as we used distance's 10th power as the relation in order to lower the sky illumination to a satisfactory level.
</p>

<p>
  Shown below are pictures of sun and the moon with atmospheric lighting incorporated:
</p>

<h2 align="middle">Screen Space Reflections</h2>




<h2 align="middle">Resources</h2>

    <p>
      https://optifine.readthedocs.io/shaders_dev.html#overview (documentation for OptiFine rendering)
<br>
https://lettier.github.io/3d-game-shaders-for-beginners/screen-space-reflection.html (Screen-space reflection)
<br>
https://bartwronski.files.wordpress.com/2014/08/bwronski_volumetric_fog_siggraph2014.pdf (Volumetric fog)
<br>
http://www.opengl-tutorial.org/intermediate-tutorials/tutorial-16-shadow-mapping/ (Shadow mapping)
<br>
We plan on using OpenGL/GLSL for our implementation as that is what Minecraft and OptiFine use.
    </p>

    <h2 align="middle">Contributions</h2>
<p>
  Shawn<br>
  Massimo<br>
  Jason<br>
  Joey
</p>


</body>
</html>
