<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Joey Zhao and Massimo Tseng, Team Bnuuy</h2>

<br><br>

<div>

<h2 align="middle">Overview</h2>
<p>In this project, we implemented a rasterizer and gave it numerous ways to sample points for display. We implemented super sampling, pixel sampling, and level sampling so we could see the effects of different combinations on an image. It was eye-opening to see in practice how the techniques we learned in class were applied to images. It puts into perspective a lot of what we take for granted in our computers and graphics.</p>

<h2 align="middle">Section I: Rasterization</h2>

<h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

<p>We rasterize triangles by sampling the middle of pixels on our screen and checking to see if the point is in the triangle. We check if the point is in the triangle with the line tests, which takes the norm of a half plane and dots it with a vector between our sampled point and a point on the triangle. We check all 3 half planes and if the dot products are all <b>>= 0</b> or <b><= 0</b>, we know the point is in the triangle. If the point is in the triangle, we fill the pixel, otherwise we don&apos;t fill it. 
</p>

<p>Our algorithm checks the bounding box of the triangle. We take the minimum and maximum x and y to get the bounding box. We then sample all of the points inside this box to see if they are in the triangle. The image below shows one of the problems with this type of basic sampling where we have jaggies due to how the triangle manages to <q>evade</q> the center 
</p>

<div align="middle">
  <table style="width=100%">
    <tr>
      <td>
        <img src="images/image2.png" align="middle" width="800px"/>
        <figcaption align="middle">test4 with default parameters with the pixel inspector on jaggies.</figcaption>
      </td>
    </tr>
  </table>
</div>


<h3 align="middle">Part 2: Antialiasing triangles</h3>

<p>The supersampling algorithm was taking every real pixel on the screen, taking sample_rate evenly spaced samples in the pixel, and then averaging out the number of samples that were in the triangle to the ones that weren’t. This means that if the triangle doesn’t go through the center of the pixel, the pixel would still be able to show some color when it wouldn’t in Task 1. This creates less jaggies and softer edges since we provide a better representation of the triangle.There is a trade off between how much we want to sample to make the image not have jaggies vs the computation cost.

</p>

<p>For our pipeline, we have to update the sample buffer to be representative since we are essentially sampling on a higher resolution screen and downsizing after. We then added loops to grab the samples in each pixel. Because of the newly scaled sample buffer, we had to also change our indexing so we moved through the buffer correctly. Finally, we also had to change how the program handled converting from the sample buffer to the frame buffer. Since we had more samples per pixel, we averaged them out and gave that color to the frame buffer.
</p>

<p>In the images below at 1, 4, and 16 samples per pixel, we see in the pixel inspector the difference supersampling is making in the antialiasing. With only 1 sample, we have a large gap where the triangle didn’t hit a single pixel center. As we increase the samples, we get better and better representation of how much of the triangle was in the pixel due to the super sampling.
</p>

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/image12.png" align="middle" width="400px"/>
          <figcaption align="middle">1 pixel sample rate.</figcaption>
        </td>
        <td>
          <img src="images/image13.png" align="middle" width="400px"/>
          <figcaption align="middle">4 pixel sample rate.</figcaption>
        </td>
      </tr>
      <br>

    </table>
  </div>

<div align="middle">
    <table style="width=100%">
        <tr>
          <img src="images/image14.png" align="middle" width="400px"/>
          <figcaption align="middle">16 pixel sample.</figcaption>
        </tr>
    </table>
</div>

<h3 align="middle">Part 3: Transforms</h3>

<p>For this task, we changed the cubeman to be hitting a serve in volleyball. He has one hand up just after tossing the ball and is preparing to hit it with his right hand. His current stance also reflects that he is learning forward into the ball for more power.</p>

<div align="middle">
    <table style="width=100%">
        <tr>
          <img src="images/image7.png" align="middle" width="800px"/>
        </tr>
    </table>
</div>

<h2 align="middle">Section II: Sampling</h2>

<h3 align="middle">Part 4: Barycentric coordinates</h3>

<p>Barycentric coordinates are a way to interpolate within a triangle. It gives us a consistent and accurate way to tell where in the triangle we are relative to all vertices. A good way for us to visualize the coordinates is through a triangle where each vertex represents red, blue, or green. Depending on how from the vertex we get, we transition the colors to more of a mix as seen in the image below.</p>

<div align="middle">
    <table style="width=100%">
        <tr>
          <img src="images/image11.png" align="middle" width="800px"/>
          <figcaption align="middle">triangle with barycentric coordinates</figcaption>
        </tr>
    </table>
</div>

<p>
    These coordinates are also crucial in helping us move from pixels to texels as the barycentric coordinates won’t change.
</p>

<div align="middle">
    <table style="width=100%">
        <tr>
          <img src="images/image1.png" align="middle" width="800px"/>
          <figcaption align="middle">Test7 with default viewing parameters </figcaption>
        </tr>
    </table>
</div>


<h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>

<p>Pixel sampling is the process where we choose which pixels from the texture to represent on the frame. We were given two triangles, one on the screen and one in the texture that mapped to each other. We then used Barycentric coordinates to move between the coordinate systems to get the texture pixels we wanted. Once the coordinate in the texture, we were then able to perform the sampling methods of nearest and bilinear. Nearest, like the name suggests, just chooses the nearest actual texel to the texture coordinate we got. However, bilinear is slightly more involved. It takes the 4 nearest texels to the sampled point and performs bilinear interpolation to find out what color we make the actual pixel. 

</p>

<p>
    The images below are pixel sampling on the left and bilinear on the right. The top images are 1 sample while the bottom are 16 samples. As we can see in the pixel inspection, the bilinear represents the longitude and latitude lines better. When there is 1 sample, we clearly see that there is better representation of the lines and less jaggies. In the 16 sample, we see it even clearer that the lines are completely represented in the bilinear sampling. However, in the nearest pixel, we see half of the longitude line missing.  

</p>

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/image15.png" align="middle" width="400px"/>
          <figcaption align="middle">1 pixel sample rate with nearest</figcaption>
        </td>
        <td>
          <img src="images/image8.png" align="middle" width="400px"/>
          <figcaption align="middle">1 pixel sample rate with bilinear</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/image4.png" align="middle" width="400px"/>
          <figcaption align="middle">16 pixel sample rate with nearest</figcaption>
        </td>
        <td>
          <img src="images/image5.png" align="middle" width="400px"/>
          <figcaption align="middle">16 pixel sample rate with bilinear</figcaption>
        </td>
      </tr>
    </table>
  </div>

<p>
    The overall biggest differences between these two methods will be when there is a sharp change in the color. Nearest pixel might look more sudden depending on if the nearest pixels color. However, with bilinear, since we sample the 4 nearest points, we have a little bit of representation of the surrounding area so the change in color won’t be as drastic, causing a “blurrier” but better image overall.
</p>

<h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>

<p>
    Level sampling is essentially finding the “best” mipmap for the texture given a screen space coordinate. What we did is find the barycentric coordinates of (x, y), (x+1, y), and (x, y+1) and found their corresponding (u,v) coordinates. Given the latter two (u,v) coordinates, we are able to compute a rough derivative with respect to each variable x and y and we used these partials to compute L using the equation provided in lecture 5, which conceptually can be thought of as taking the max between the two Jacobians. Then, a log is taken (with correct clamping beforehand) and we use this returned log2 value for the levels. 


</p>

<p>
	The three sampling techniques each have different benefits and costs. Increasing the samples per pixels is fantastic for jaggies but it increases the size of storage and computation exponentially as you want to sample more. However, the higher you go, the greater the antialiasing. Pixel sampling is overall pretty cheap. It was essentially just a bit of arithmetic without having much more computation than low level supersampling. Their antialiasing isn’t too comparable because supersampling affects edges more. Finally, level sampling is also great. It’s significantly cheaper than high levels of supersampling but is much faster. However, the drawback is that with mipmap levels, you do a decent amount of calculations for obtaining the level or interpolating; the memory usage is only 4/3x that of only level 0. Its antialiasing is comparable to supersampling while being cheaper.
</p>

<div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/image9.png" align="middle" width="400px"/>
          <figcaption align="middle">Level zero and nearest</figcaption>
        </td>
        <td>
          <img src="images/image6.png" align="middle" width="400px"/>
          <figcaption align="middle">Level zero and bilinear</figcaption>
        </td>
      </tr>
      <br>
      <tr>
        <td>
          <img src="images/image10.png" align="middle" width="400px"/>
          <figcaption align="middle">Nearest level and nearest</figcaption>
        </td>
        <td>
          <img src="images/image3.png" align="middle" width="400px"/>
          <figcaption align="middle">Nearest level and bilinear</figcaption>
        </td>
      </tr>
    </table>
  </div>

</body>
</html>